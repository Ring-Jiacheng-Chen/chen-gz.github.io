{"pages":[],"posts":[{"title":"Basic Information","text":"Basic Information The systems to be studied in this text are limited to linear systems. Using the concept of linearity, we develop in Chapter 2 that every linear system can be described by \\[ \\mathbf{y}(t)=\\int_{t_{0}}^{t} \\mathbf{G}(t, \\tau) \\mathbf{u}(\\tau) d \\tau \\] This equation describes the relationship between the input u and output y and is called the input–output or external description. If a linear system is lumped as well, then it can also be described by \\[ \\begin{aligned} \\dot{\\mathbf{x}}(t) &amp;=\\mathbf{A}(t) \\mathbf{x}(t)+\\mathbf{B}(t) \\mathbf{u}(t) \\\\ \\mathbf{y}(t) &amp;=\\mathbf{C}(t) \\mathbf{x}(t)+\\mathbf{D}(t) \\mathbf{u}(t) \\end{aligned} \\] \\(Equation (1.2)\\) is a set of ﬁrst-order differential equations and \\(Equation (1.3)\\) is a set of algebraic equations. They are called the internal description of linear systems. Because the vector x is called the state, the set of two equations is called the state-space or, simply, the state equation. If a linear system has, in addition, the property of time invariance, then \\(Equations (1.1)\\) through \\((1.3)\\) reduce to \\[ \\mathbf{y}(t)=\\int_{0}^{t} \\mathbf{G}(t-\\tau) \\mathbf{u}(\\tau) d \\tau \\] and \\[ \\begin{array}{c} {\\dot{\\mathbf{x}}(t)=\\mathbf{A} \\mathbf{x}(t)+\\mathbf{B u}(t)} \\\\ {\\mathbf{y}(t)=\\mathbf{C x}(t)+\\mathbf{D} \\mathbf{u}(t)}\\end{array} \\] For this class of linear time-invariant systems, the Laplace transform is an important tool in analysis and design. Applying the Laplace transform to (1.4) yields \\[ \\hat{\\mathbf{y}}(s)=\\hat{\\mathbf{G}}(s) \\hat{\\mathbf{u}}(s) \\] where a variable with a circumﬂex denotes the Laplace transform of the variable. The function \\(\\hat{G}(s)\\) is called the transfer matrix. Both \\((1.4)\\) and \\((1.7)\\) are input–output or external descriptions. The former is said to be in the time domain and the latter in the frequency domain. \\(Equations (1.1)\\) through \\((1.6)\\) are called continuous-time equations because their time defines SISO A system with only one input terminal and only one output terminal is called a single-variable system or a single-input single-output (SISO) system. MIMO A system with two or more input terminals and/or two or more output terminals is called a multi-variable system. More speciﬁcally, we can call a system a multi-input multi-output (MIMO) system if it has two or more input terminals and output terminals. SIMO A single-input multi-output (SIMO) system if it has one input terminal and two or more output terminals. continuous-time A system is called a continuous-time system if it accepts continuous-time signals as its input and generates continuous-time signals as its output. discrete-time A system is called a discrete-time system if it accepts discrete-time signals as its input and generates discrete-time signals as its output. memoryless system A system is called a memoryless system if its output y(t 0 ) depends only on the input applied at t 0 ; it is independent of the input applied before or after t 0 . This will be stated succinctly as follows: current output of a memoryless system depends only on current input; it is independent of past and future inputs. causal or non-anticipatory A system is called a causal or non-anticipatory system if its current output depends on past and current inputs but not on future input. If a system is not causal, then its current output will depend on future input. In other words, a non-causal system can predict or anticipate what will be applied in the future. No physical system has such capability. Therefore every physical system is causal and causality is a necessary condition for a system to be built or implemented in the real world. This text studies only causal systems. Using the state at \\(t_0\\) , we can express the input and output of a system as \\[ \\left. \\begin{array}{l}{\\mathbf{x}\\left(t_{0}\\right)} \\\\ {\\mathbf{u}(t), t \\geq t_{0}}\\end{array} \\right\\} \\rightarrow \\mathbf{y}(t), \\quad t \\geq t_{0} \\] It means that the output is partly excited by the initial state at t 0 and partly by the input applied at and after t 0 . In using (2.1), there is no more need to know the input applied before t 0 all the way back to −∞. Thus (2.1) is easier to track and will be called a state-input–output pair. A system is said to be lumped if its number of state variables is ﬁnite or its state is a lumped A system is said to be lumped if its number of state variables is ﬁnite or its state is a ﬁnite vector. The network in Fig. 2.2 is clearly a lumped system; its state consists of three numbers. distributed A system is called a distributed system if its state has inﬁnitely many state variables. The transmission line is the most well known distributed system. linear system additivity, homogeneity and superpositition Systems A system is called a linear system if for every t_0 and any two state-input–output pairs \\[ \\left. \\begin{array}{l}{\\mathbf{x}\\left(t_{0}\\right)} \\\\ {\\mathbf{u}(t), t \\geq t_{0}}\\end{array}\\right\\} \\rightarrow \\mathbf{y}(t), \\quad t \\geq t_{0} \\] for \\(i =1,2\\), we have \\[ \\left. \\begin{array}{rl}{\\mathbf{x}_{1}\\left(t_{0}\\right)+\\mathbf{x}_{2}\\left(t_{0}\\right)} &amp; {} \\\\ {\\mathbf{u}_{1}(t)+\\mathbf{u}_{2}(t),} &amp; {t \\geq t_{0}}\\end{array}\\right\\} \\rightarrow \\mathbf{y}_{1}(t)+\\mathbf{y}_{2}(t), \\quad t \\geq t_{0} \\text { (additivity) } \\] and \\[ \\left. \\begin{array}{l}{\\alpha \\mathbf{x}_{1}\\left(t_{0}\\right)} \\\\ {\\alpha \\mathbf{u}_{1}(t), \\quad t \\geq t_{0}}\\end{array} \\right\\} \\rightarrow \\alpha \\mathbf{y}_{1}(t), \\quad t \\geq t_{0} \\text { (homogeneity) } \\] for any real constant \\(\\alpha\\). The ﬁrst property is called the additivity property, the second, the homogeneity property. These two properties can be combined as \\[ \\left. \\begin{array}{l}{\\alpha_{1} \\mathbf{x}_{1}\\left(t_{0}\\right)+\\alpha_{2} \\mathbf{x}_{2}\\left(t_{0}\\right)} \\\\ {\\alpha_{1} \\mathbf{u}_{1}(t)+\\alpha_{2} \\mathbf{u}_{2}(t), \\quad t \\geq t_{0}}\\end{array} \\right \\} \\rightarrow \\alpha_{1} \\mathbf{y}_{1}(t)+\\alpha_{2} \\mathbf{y}_{2}(t), \\quad t \\geq t_{0} \\] for any real constants \\(\\alpha_1\\) and \\(\\alpha_2\\), and is called the superposition property. A system is called a nonlinear system if the superposition property does not hold. zero input response If the input \\(\\mathbf{u}(t)\\) is identically zero for \\(t \\geq t_{0}\\) , then the output will be excited exclusively by the initial state \\(\\mathbf{x}\\left(t_{0}\\right).\\) This output is called the zero-input response and will be denoted by\\(\\mathbf{y}_{z i}\\) or \\[ \\left. \\begin{array}{l}{\\mathbf{x}\\left(t_{0}\\right)} \\\\ {\\mathbf{u}(t) \\equiv \\mathbf{0}, t \\geq t_{0}}\\end{array}\\right \\}\\rightarrow \\mathbf{y}_{z i}(t), \\quad t \\geq t_{0} \\] zero state response If the initial state \\(\\mathbf{x}\\left(t_{0}\\right)\\) is zero, then the output will be excited exclusively by the input. This output is called the zero-state response and will be denoted by \\(\\mathbf{y}_{z s}\\) or \\[ \\left. \\begin{array}{rl}{\\mathbf{x}\\left(t_{0}\\right)=} {\\mathbf{0}} \\\\ {\\mathbf{u}(t),} 4 {t \\geq t_{0}}\\end{array}\\right\\} \\rightarrow \\mathbf{y}_{z s}(t), \\quad t \\geq t_{0} \\] input-output description Consequently, the input u(t) can be expressed symbolically as \\[ u(t) \\approx \\sum_{i} u\\left(t_{i}\\right) \\delta_{\\Delta}\\left(t-t_{i}\\right) \\Delta \\] Let \\(g_{\\Delta}\\left(t, t_{i}\\right)\\) be the output at time \\(t\\) excited by the pulse \\(u(t)=\\delta_{\\Delta}\\left(t-t_{i}\\right)\\) applied at time \\(t_{i}\\). Then we have \\[ \\begin{aligned} \\delta_{\\Delta}\\left(t-t_{i}\\right) &amp; \\rightarrow g_{\\Delta}\\left(t, t_{i}\\right) \\\\ \\delta_{\\Delta}\\left(t-t_{i}\\right) u\\left(t_{i}\\right) \\Delta &amp; \\rightarrow g_{\\Delta}\\left(t, t_{i}\\right) u\\left(t_{i}\\right) \\Delta \\quad \\text { (homogeneity) } \\\\ \\sum_{i} \\delta_{\\Delta}\\left(t-t_{i}\\right) u\\left(t_{i}\\right) \\Delta &amp; \\rightarrow \\sum_{i} g_{\\Delta}\\left(t, t_{i}\\right) u\\left(t_{i}\\right) \\Delta \\quad \\text { (additivity) } \\end{aligned} \\] Thus the output \\(y(t)\\) excited by the input \\(u(t)\\) can be approximated by \\[ y(t) \\approx \\sum_{i} g_{\\Delta}\\left(t, t_{i}\\right) u\\left(t_{i}\\right) \\Delta \\] Now if \\(\\Delta\\) approaches zero, the pulse \\(\\delta_{\\Delta}\\left(t-t_{i}\\right)\\) becomes an impulse at \\(t_{i},\\) denoted by \\(\\delta\\left(t-t_{i}\\right),\\) and the corresponding output will be denoted by \\(g\\left(t, t_{i}\\right) .\\) As \\(\\Delta\\) approaches zero, the approximation in \\((2.2)\\) becomes an equality, the summation becomes an integration, the discrete \\(t_{i}\\) becomes a continuum and can be replaced by \\(\\tau,\\) and \\(\\Delta\\) can be written as \\(d \\tau .\\) Thus \\((2.2)\\) becomes \\[ y(t)=\\int_{-\\infty}^{\\infty} g(t, \\tau) u(\\tau) d \\tau \\] Note that \\(g(t, \\tau)\\) is a function of two variables. The second variable denotes the time at which the impulse input is applied; the ﬁrst variable denotes the time at which the output is observed. Because \\(g(t,\\tau)\\) is the response excited by an impulse, it is called the impulse response. If a system is causal, the output will not appear before an input is applied. Thus we have \\[ \\text { Causal } \\Longleftrightarrow g(t, \\tau)=0 \\text { for } t&lt;\\tau \\] relax A system is said to be relaxed at \\(t_0\\) if its initial state at \\(t_0\\) is 0. In this case, the output \\(y(t)\\), for \\(t ≥ t_0\\) , is excited exclusively by the input \\(u(t)\\) for \\(t \\geq 0\\). In conclusion, every linear system that is causal and relaxed at \\(t_0\\) can be described by \\[ \\mathbf{G}(t, \\tau)=\\left[\\begin{array}{cccc}{g_{11}(t, \\tau)} &amp; {g_{12}(t, \\tau)} &amp; {\\cdots} &amp; {g_{1 p}(t, \\tau)} \\\\\\ {g_{21}(t, \\tau)} &amp; {g_{22}(t, \\tau)} &amp; {\\cdots} &amp; {g_{2 p}(t, \\tau)} \\\\\\ {\\vdots} &amp; {\\vdots} &amp; {} &amp; {\\vdots} \\\\\\ {g_{q 1}(t, \\tau)} &amp; {g_{q 2}(t, \\tau)} &amp; {\\cdots} &amp; {g_{q p}(t, \\tau)}\\end{array}\\right] \\] where \\[ \\mathbf{y}(t)=\\int_{t_{0}}^{t} \\mathbf{G}(t, \\tau) \\mathbf{u}(\\tau) d \\tau \\] and \\(g_{ij}(t,\\tau)\\) is the response at time \\(t\\) at the \\(i\\)th output terminal due to an impulse applied at time \\(\\tau\\) at the \\(j\\) th input terminal, the inputs at other terminals being identically zero. That is, \\(g_i{ij}(t, \\tau )\\) is the impulse response between the \\(j\\) th input terminal and the ith output terminal. Thus G is called the impulse response matrix of the system. Linear Time-Invariant(LTI) Systems time invariant A system is said to be time invariant if for every state-input–output pair \\[ \\left. \\begin{array}{l}{\\mathbf{x}\\left(t_{0}\\right)} \\\\\\ {\\mathbf{u}(t), t \\geq t_{0}}\\end{array}\\right\\} \\rightarrow \\mathbf{y}(t), \\quad t \\geq t_{0} \\] and any \\(T\\), we have \\[ \\left. \\begin{array}{l}{\\mathbf{x}\\left(t_{0}+T\\right)} \\\\ {\\mathbf{u}(t-T), t \\geq t_{0}+T}\\end{array}\\right\\} \\rightarrow \\mathbf{y}(t-T), t \\geq t_{0}+T \\quad \\text { (time shifting) } \\] It means that if the initial state is shifted to time \\(t_0 + T\\) and the same input waveform is applied from \\(t_0 + T\\) instead of from \\(t_0\\) , then the output waveform will be the same except that it starts to appear from time \\(t_0 + T\\) . In other words, if the initial state and the input are the same, no matter at what time they are applied, the output waveform will always be the same. Therefore, for time-invariant systems, we can always assume, without loss of generality, that \\(t_0 = 0\\). If a system is not time invariant, it is said to be time varying. this also means \\(g(t) = 0, t&lt;t_0\\) Here need to add some comment. When I have time.","link":"/2019/09/13/Linear-Control-System/Basic-Information/"},{"title":"Buck Boost Converter","text":"Buck Boost Converter buck-boost converter revert output voltage Another converter, the buck-boost converter, can either increase or decrease the magnitude of the voltage, but the polarity is inverted. So with a positive input voltage, the ideal buck-boost converter can produce a negative output voltage of any magnitude. circuit Buck-Boost-Converter why this is a buck-boost converter when mos on, the circuit at status 1: \\[ v_L = V_g \\\\ i_C = \\frac{v}{R} \\approx \\frac{V}{R} \\\\ \\frac{di_L}{dt} = \\frac{v_L}{L} \\approx \\frac{V_g}{L} \\\\ \\frac{dv_C}{dt} = \\frac{i_C}{C} = \\frac{v}{RC} \\approx \\frac{V}{RC} \\] when mos off, the circuit at status 2: \\[ v_L = v \\approx V \\\\ i_C = i_L + i_o \\approx I_L + I_o \\\\ \\frac{di_L}{dt} = \\frac{v_L}{L} = \\frac{v}{L} \\approx \\frac{V}{L} \\\\ \\frac{dv_C}{dt} = \\frac{i_C}{C} = \\frac{i_L + i_0}{C} \\approx \\frac{I_L+I_o}{C} \\] to find out the relationship between input voltage and output voltage equate \\(&lt;v_L&gt; = 0\\). \\[ \\frac{V_g}{L}DT_s + \\frac{V}{L}D'T_s = 0 \\] then \\[ V = -\\frac{V_g D }{D'} \\] from the formula, when \\(D&lt;D'\\) is a buck converter. Otherwise this is a boost converter. we can figure out that \\[ D = \\frac{V}{V-V_g} \\] set \\(&lt;i_C&gt; = 0\\) \\[ \\frac{V}{RC}DT_s + \\frac{I_L+I_o}{C}D'T_s = 0 \\] \\[ I_o = -I_L D' \\\\ I_L = -\\frac{I_o}{D'} = -\\frac{V}{RD'} \\] ripple to find \\(\\Delta i_L\\) notice that \\(\\frac{di_L}{dt}\\) so we can get that \\[ 2\\Delta i_L = \\frac{V_g}{L}DT_s \\] to find \\(\\Delta v\\) notice that \\(\\frac{dv_C}{dt}\\) and $v_C = v $ so we can get that \\[ 2\\Delta v_C = \\frac{V}{RC}DT_s \\\\ \\Delta v_C = \\frac{-V_g D^2 T_s} {2RC(1-D)} \\]","link":"/2019/09/16/Power-Electric/Buck-Boost-Converter/"},{"title":"Buck Converter","text":"Buck Converter equations \\[ v_L = v_g - V \\approx V_g -V \\] \\[ i_c = i_L - \\frac{V}{R} = i_L - I_o \\approx I - \\frac{V}{R} \\] \\[ \\frac{dv_c}{dt} = \\frac{i_c}{C} \\approx \\frac{I-\\frac{V}{R}}{C} \\] \\[ \\frac{di_l}{dt} = \\frac{v_L}{L} \\approx \\frac{V_g-V}{L} \\] circuit buck converter relationship of input and output voltage The relationship between input voltage \\(V_g\\) and output voltage $ V_s$: \\[ V_{s}=\\frac{1}{T_{s}} \\int_{0}^{T_{s}} v_{s}(t) d t=D V_{g} \\] DC component of \\(v_s(t)\\) As illustrated in Fig. \\(2.2 .\\) the integral is given by the area under the curve, or \\(D T_{s} V_{g}\\) . The average value is therefore \\[ \\left\\langle v_{s}\\right\\rangle=\\frac{1}{T_{s}}\\left(D T_{s} V_{g}\\right)=D V_{g} \\] So the average value, or DC component, of \\(v_{s}(t)\\) is equal to the duty cycle times the DC input voltage \\(V_{g}\\). the ripple of inductor current The inductor voltage \\(v_{L}(t)\\) is then given by \\[ v_{L}=V_{x}-v(t) \\] The inductor voltage can be found by use of the definition \\[ v_{L}(t)=L \\frac{d i_{L}(t)}{d t} \\] Thus, during the first interval, when \\(v_{L}(t)\\) is approximately \\(\\left(V_{x}-V\\right),\\) the slope of the inductor current waveform is \\[ \\frac{d i_{L}(t)}{d t}=\\frac{v_{L}(t)}{L} \\approx \\frac{v_{g}-v}{L} \\] \\[ \\frac{d i_{L}(t)}{d t} \\approx-\\frac{V}{L} \\] the inductor current ripple \\(\\Delta i_{L}\\) since we know the slope of the inductor curring the first subinterval, and we also know the length of the first subinterval, we can calculate the ripple magnitude. The \\(i_{t}(t)\\) waveform is symmetrical about \\(I,\\) and hence during the first so the change in current increases by 2\\(\\Delta i_{L}\\) (since \\(\\Delta i_{1}\\) is the peak ripple, the peak-to-peak ripple is \\(2\\Delta i_{l}\\)). So the change in current, \\(2 \\Delta i_{L},\\) is equal to the slope (the applied inductor voltage divided by \\(L\\) ) times the length of the first subinterval \\(\\left(D T_{s}\\right)\\) : \\[ \\left(2 \\Delta i_{L}\\right)=\\left(\\frac{V_{g}-V}{L}\\right)\\left(D T_{\\mathrm{s}}\\right) \\] \\[ \\Delta i_{L}=\\frac{V_{g}-V}{2 L} D T_{\\mathrm{s}} \\] the Capacitor voltage ripple \\(\\Delta v_{C}\\) why can not use \\(\\frac{dv_c}{dt}\\) to calcutlate why need use \\(\\Delta i_L\\) to calculate the value of \\(\\Delta v_C\\) By the capacitor relation \\(Q=C V\\) \\[ q=C(2 \\Delta v) \\] \\[ q=\\frac{1}{2} \\Delta i_{L} \\frac{T_{s}}{2} \\] \\[ \\Delta v=\\frac{\\Delta i_{L} T_{s}}{8 C} \\] reduce peak to peak ripple The inductor value can be chosen such that a desired current ripple \\(\\Delta i_{L}\\) is attained. Solution of \\(Eq. (2.15)\\) for the inductance \\(L\\) yields \\[ L=\\frac{V_{k}-V}{2 \\Delta i_{L}} D T_{\\mathrm{s}} \\] fit continue conduction mode get \\(L_{min}\\) \\[ L=\\frac{V_{g}-V}{2 \\Delta i_{l}} D T_{\\mathrm{s}} \\]","link":"/2019/09/13/Power-Electric/Buck-Converter/"},{"title":"Foundation and Basic Concept","text":"note: most things are copied from book, not write by myself and this book can get from Google. I only copy important things to here and add some comments. symbols Duty cycle: D single pole double throw: SPDT. output voltage \\(v_{s}(t)\\). converter input voltage \\(V_{g}\\). The complement of the duty ratio, \\(D^{\\prime},\\) is defined as \\((1-D)\\). DC component of \\(v_s(t)\\): From Fourier analysis, we know that the DC component of \\(v_{s}(t)\\) is given by its average value \\(\\left\\langle v_{s}\\right\\rangle,\\) or \\[ \\left\\langle v_{s}\\right\\rangle=\\frac{1}{T_{s}} \\int_{0}^{T_{s}} v_{s}(t) d t \\] ## position of inductor The buck converter is just one of many possible switching converters. Two other commonly used converters, which perform different voltage conversion functions, are illustrated in Fig. \\(2.5 .\\) In the boost converter, the positions of the inductor and switch are reversed. balance rule for inductor voltage and capacitor current The principles of inductor volt-second balance and capacitor charge balance are derived; these can be used to solve for the inductor currents and capacitor voltages of switching converters. small-ripple and linear-ripple approximation So it is nearly always a good approximation to assume that the magnitude of the switching ripple is much smaller than the DC component: \\[ \\left|v_{\\text {ripple}}\\right|&lt;V \\] Therefore, the output voltage \\(v(t)\\) is well approximated by its DC component \\(V,\\) with the small ripple term \\(v_{ripple}(t)\\) neglected: \\[ v(t) \\approx V \\] ## inductor voltage and conductor current inductor voltage The inductor voltage can be found by use of the definition \\[ v_{L}(t)=L \\frac{d i_{L}(t)}{d t} \\] Capacitor current \\[ i_c(t) = C \\frac{du_c(t)}{dt} \\] The balance of inductor and capacitor Inductor voltage balance the principle of inductor volt-second balance. Given the defining relation of an inductor: \\[ v_{L}(t)=L \\frac{d i_{L}(t)}{d t} \\] Integration over one complete switching period, say from \\(t=0\\) to \\(T_{s}\\) , yields \\[ i_{L}\\left(T_{s}\\right)-i_{L}(0)=\\frac{1}{L} \\int_{0}^{T_{s}} v_{L}(t) d t \\] Therefore, in steady state the integral of the applied inductor voltage must be zero: \\[ 0=\\int_{0}^{T_{s}} v_{L}(t) d t \\] ### Capacitor current balance Similar arguments can be applied to capacitors. The defining equation of a capacitor is \\[ i_{C}(t)=C \\frac{d v_{C}(t)}{d t} \\] Integration of this equation over one switching period yields \\[ v_{C}\\left(T_{s}\\right)-v_{C}(0)=\\frac{1}{C} \\int_{0}^{T_{s}} i_{C}(t) d t \\] In steady state, the net change over one switching period of the capacitor voltage must be zero, so that the left-hand side of \\(Eq. (2.26)\\) is equal to zero. Therefore, in equilibrium the integral of the capacitor current over one switching period (having the dimensions of amp-seconds, or charge) should be zero. There is no net change in capacitor charge in steady state. An equivalent statement is This should be an intuitive result. If a DC current is applied to a capacitor, then the \\[ 0=\\frac{1}{T_{s}} \\int_{0}^{T_{s}} i_{c}(t) d t=\\left\\langle i_{c}\\right\\rangle \\] The average value, or DC component, of the capacitor current must be zero in equilibrium. continue conduction mode current must over zero, if not satisfied continue conduction mode, then when switch to status 2, two component will off! from continue conduction mode we can define \\(L_{min}\\) to satisfy continue conduction mode. M(D) of various converter","link":"/2019/09/13/Power-Electric/Foundation-And-Basic-Concept/"},{"title":"SEPIC-Converter","text":"SEPIC-Converter Single-ended primary-inductor converter Principle when mos on, the circuit work at status 1 from the firgure we can see that we have 3 circle. \\[ v_{L1} = V_g \\\\ i_{C1} = -i_{L2} \\approx -I_{L2} \\\\ v_{L2} = v_{C1} \\approx V_{C1} \\\\ i_{C2} = -\\frac{v_o}{R} \\approx -\\frac{V_o}{R} \\] \\[ \\frac{di_{L_1}}{dt} = \\frac{v_{L1}}{L_1} = \\frac{V_g}{L_1} \\\\ \\frac{du_{C_1}}{dt} = \\frac{i_{C_1}}{C_1} = \\frac{-i_{L_2}}{C_1} \\approx \\frac{-I_{L_2}}{C_1} \\\\ \\frac{di_{L_2}}{dt} = \\frac{v_{L_2}}{L_2} = \\frac{v_{C_1}}{L_2} \\approx \\frac{V_{C_1}}{L_2} \\\\ \\frac{du_{C_2}}{dt} = \\frac{i_{C_2}}{C_2} = -\\frac{v_o}{RC_2} \\approx -\\frac{V_o}{RC_2} \\\\ \\] when mos off, the circuit work at status 2 from the figure we have equations: \\[ v_{L1} = V_g - v_{C_1} - v_o \\approx V_g - V_{C_1} - V_o\\\\ i_{C1} = i_{L_1} \\approx I_{L_1} \\\\ v_{L2} = -v_o \\approx -V_o \\\\ i_{C2} = i_{L_1} + i_{L_2} - \\frac{v_o}{R} \\approx I_{L_1} + I_{L_2} - \\frac{V_o}{R} \\] \\[ \\frac{di_{L_1}}{dt} = \\frac{V_g-v_{C_1}-v_o}{L_1} = \\frac{V_g-V_{C_1}-V_o}{L_1} \\\\ \\frac{du_{C_1}}{dt} = \\frac{i_{C_1}}{C_1} = \\frac{i_{L_1}}{C_1} \\approx \\frac{I_{L_1}}{C_1} \\\\ \\frac{di_{L_2}}{dt} = \\frac{v_{L_2}}{L_2} = \\frac{-v_0}{L_2} \\approx \\frac{-V_{o}}{L_2} \\\\ \\frac{du_{C_2}}{dt} = \\frac{i_{C_2}}{C_2} = \\frac{i_{L_1}-\\frac{v_o}{R}}{C_2} \\approx \\frac{I_{L_1}-\\frac{V_o}{R}}{C_2} \\] to set \\(&lt;v_{L_1}&gt; = 0\\) \\[ \\frac{V_g}{L_1}DT_s + \\frac{V_g - V_{C_1} - V_o}{L_1}D'T_s = 0 \\] to set \\(&lt;i_{C_1}&gt; = 0\\) \\[ \\frac{-I_{L_2}}{C_1}DT_s + \\frac{I_{L_1}}{C_1} D'T_s = 0 \\] to set $&lt;u_{L_2}&gt; = 0 $ \\[ \\frac{V_{C_1}}{L_2}DT_s - \\frac{V_o}{L_2}D'T_s = 0 \\] to set \\(&lt;i_{C_2}&gt; = 0\\) \\[ -\\frac{V_o}{RC_2}DT_s +\\frac{I_{L_1} + I_{L_2} -\\frac{V_o}{R}}{C_2}D'T_s = 0 \\] from \\(equation (7)\\) \\[ V_{C_1}D = V_o D' \\] from \\(euqation(5)\\) \\[ V_g D + (V_g - V_{C_1} - V_o)D' = 0 \\\\ V_g + (-\\frac{V_oD'}{D} - V_o)D' =0 \\\\ V_o = \\frac{V_g D}{D'} \\] from \\(equation(9)\\) \\[ V_o = \\frac{V_{C_1}D}{D'} \\] assiociate \\(equation(9),(11)\\) we get that \\[ V_g = V_{C_1} \\] from \\(equation(6)\\) \\[ -I_{L_2}D + I_{L_1}D' = 0 \\\\ I_{L_2} = \\frac{I_{L_1}D'}{D} \\] from \\(euqaiton (8)\\) \\[ -\\frac{V_o}{R} +(I_{L_1}+I_{L_2})D' = 0\\\\ I_{L_1}+I_{L_2} = \\frac{V_o}{RD'} = \\frac{V_gD}{RD'D'} \\\\ I_{L_1}+\\frac{I_{L_1}D'}{D} = \\frac{V_gD}{RD'D'} \\\\ \\frac{I_{L_1}}{D} = \\frac{V_gD}{RD'D'} \\\\ I_{L_1} = (\\frac{D}{D'})^2 \\frac{V_g}{R} \\] from \\(equation(13)\\) \\[ I_{L_2} =\\frac{D}{D'} \\frac{V_g}{R} \\] use \\(\\frac{du_{C_1}}{dt} = \\frac{i_{C_1}}{C_1} = \\frac{-i_{L_2}}{C_1} \\approx \\frac{-I_{L_2}}{C_1} \\\\\\) we can get that \\[ 2 \\Delta v_{C_1} = \\frac{-I_{L_2}}{C_1}DT_s \\\\ \\Delta v_{C_1} = \\frac{D^2}{D'}T_S\\frac{V_g}{2RC_1} \\] use \\(\\frac{du_{C_2}}{dt} = \\frac{i_{C_2}}{C_2} = -\\frac{v_o}{RC_2} \\approx -\\frac{V_o}{RC_2} \\\\\\) \\[ 2\\Delta v_o = \\frac{V_o}{RC_2}DT_s \\\\ \\Delta v_o = \\frac{D^2}{D'}T_s\\frac{V_g}{2RC_2} \\] use $ = = $ \\[ 2\\Delta i_{L_1} = \\frac{V_g}{L_1}DT_s \\\\ \\Delta i_{L_1} = \\frac{V_g}{2L_1}DT_s \\\\ \\] use \\(\\frac{di_{L_2}}{dt} = \\frac{v_{L_2}}{L_2} = \\frac{-v_0}{L_2} \\approx \\frac{-V_{o}}{L_2} \\\\\\) \\[ 2\\Delta i_{L_2} = \\frac{V_o}{L_2}D'T_s \\\\ \\Delta i_{L_2} = \\frac{V_gD}{2L_2}T_s \\\\ \\]","link":"/2019/09/14/Power-Electric/SEPIC-Converter/"},{"title":"Probability and Random Processes","text":"everything is copied from book The Sample Space outcome or sample point We define an outcome or sample point of a ran- dom experiment as a result that cannot be decomposed into other results. When we perform a random experiment, one and only one outcome occurs. The sample space S of a random experiment is defined as the set of all possible outcomes. We call S a discrete sample space if S is countable; that is, its outcomes can be put into one-to-one correspondence with the positive integers. We call S a continuous sample space if S is not countable. Events Events correspond to susbsets of S(sample space). correspond to subsets of S.Two events of special interest are the certain event, S, which consists of all outcomes and hence always occurs, and the impossible or null event, \\(\\emptyset\\), which contains no outcomes and hence never occurs. An event from a discrete sample space that consists of a single outcome is called an elementary event.","link":"/2019/09/16/Probability-and-Random-Processes/Basic-Information/"}],"tags":[],"categories":[{"name":"linear-control-system","slug":"linear-control-system","link":"/categories/linear-control-system/"},{"name":"power electric","slug":"power-electric","link":"/categories/power-electric/"},{"name":"First","slug":"linear-control-system/First","link":"/categories/linear-control-system/First/"},{"name":"basic electric elements","slug":"basic-electric-elements","link":"/categories/basic-electric-elements/"},{"name":"number theory","slug":"number-theory","link":"/categories/number-theory/"},{"name":"Probability and Random Processes","slug":"Probability-and-Random-Processes","link":"/categories/Probability-and-Random-Processes/"}]}